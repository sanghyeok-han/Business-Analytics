{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트마이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the process of deriving high-quality information\n",
    "from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Document를 Sentence의 집합으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 동일한 의미의 단어가 다른 형태를 갖는 것을 보완"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 단수 – 복수, 현재형 – 미래형 등 단어의 다양한 변형을 하\n",
    "나로 통일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 사전을 이용하여 단어의 원형을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 토큰화와 정규화 작업을 통해 나누어진 형태소(의미를\n",
    "가지는 최소단위)에 대해 품사를 결정하여 할당하는 작\n",
    "업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 형태소 분석의 결과인 각 형태소들을 서로 겹치지 않\n",
    "으면서 의미가 있는 구로 묶어나가는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개체명 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 텍스트로부터 뭔가 의미 있는 정보를 추출하기\n",
    "위한 방법으로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 단어의 유/무 대신 단어\n",
    "가 문서에 나타난 횟수로\n",
    "표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 단어의 count를 단어가 나타난 문서의 수로 나눠서 자주\n",
    "등장하지 않는 단어의 weight를 올림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a popular method for text\n",
    "categorization, the problem of judging documents as\n",
    "belonging to one category or the other with word\n",
    "frequencies as the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 종속 변수가 범주형 데이터를 대상으로 하며, 입력 데이터\n",
    "가 주어졌을 때 해당 데이터의 결과가 특정 분류로 나뉘기\n",
    "때문에 일종의 분류 (classification) 기법에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 목적함수에 추정할 계수(parameter)\n",
    "에 대한 L2 norm(규제항)을 추가하\n",
    "여 모형의 과적합을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L1 norm을 규제항으로 사용함으로\n",
    "써 0에 가까운 계수를 0으로 만들\n",
    "어 영향을 거의 미치지 않는 단어\n",
    "들을 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 소비자의 감성과 관련된 텍스트 정보를 자동으로 추출하\n",
    "는 텍스트 마이닝(Text Mining) 기술의 한 영역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> feature extraction\n",
    "starts from an initial set of\n",
    "measured data and builds\n",
    "derived values (features)\n",
    "intended to be informative\n",
    "and non-redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주성분 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터의 분산을 최대한\n",
    "보존하는 새로운 축을 찾\n",
    "아 변환함으로써 차원을\n",
    "축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA(Latent Semantic Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a technique in natural language processing, in particular\n",
    "distributional semantics, of analyzing relationships between\n",
    "a set of documents and the terms they contain by producing\n",
    "a set of concepts related to the documents and terms. LSA\n",
    "assumes that words that are close in meaning will occur in\n",
    "similar pieces of text (the distributional hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특이값 분해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 주어진 dtm(document term matrix, A)을 $A=UΣV^T$의 형태로\n",
    "분해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Infer the set of topics that were responsible for generating a\n",
    "collection of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> one-hot-encoding으로 표현된 단어를 dense vector로 변환하고 변환된 vector를 이용하여 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 각 단어를 모든 문서에서 사용된 단어들의 수 길이의 벡\n",
    "터로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 문장에 나타난 단어들의 순서를 이용해 word embedding\n",
    "을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이전의 대표적인 임베딩 기법인 Word2Vec이나 GloVe 등\n",
    "이 동일한 단어가 문맥에 따라 전혀 다른 의미를 가지는\n",
    "것을 반영하지 못하는 것에 비해, ELMo는 이러한 문맥을\n",
    "반영하기 위해 개발된 사전 훈련된 언어 모델을 사용하는 워드 임베딩 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> storing knowledge gained while solving one problem\n",
    "and applying it to a different but related problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 정보량을 물리학의 에너지 함수로 표현하며 차원을 변경하면서 원래의 정보량 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> encoder로 차원을 축소하\n",
    "고 decoder로 다시 복원\n",
    "했을 때, 원래의 X와 복원\n",
    "한 X’이 최대한 동일하도\n",
    "록 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> contiguous sequence of n items from a given sample of text or speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> RNN에서 직통 통로를 만들어 RNN의 문제를 해결 (긴 문장에서 앞부분의 단어들도 충분히 학습 가능해짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 양방향으로 LSTM을 구성\n",
    "하여 두 결과를 합침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이미지 처리를 위해 개발된 신경망이며 텍스트마이닝에도 사용 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> encoder, decoder의 구조를 가지며 문장을 입력해서 문장을 결과를 출력함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 출력에 나온 어떤 단어는 입력\n",
    "에 있는 특정 단어들에 민감한\n",
    "것에 착안하여 입력의 단어들로부터 출력 단어에 직접 링크를 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer (Self-attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Attention에서 입력 단어들끼리도 상호연관성이 있는 것에 착안하여 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 양방향 transformer 인코더를 사용함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
